{"id":"cardinalsin-1n1","title":"B8: Consolidate NANOS_PER_HOUR constant","description":"NANOS_PER_HOUR defined separately in local.rs:56 and s3.rs:98 plus inlined values. Move to a single shared constant in metadata/mod.rs. ~15 LOC.","status":"in_progress","priority":3,"issue_type":"task","created_at":"2026-02-09T09:28:33.594983-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:49.803807-07:00","external_ref":"gh-43","dependencies":[{"issue_id":"cardinalsin-1n1","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:32:31.146207-07:00","created_by":"import"}]}
{"id":"cardinalsin-2q1","title":"D-integration: WAL integration into ingester write path + recovery protocol","description":"After WAL core: Integrate WAL into Ingester::write(), add truncation after S3 flush, implement recovery protocol on startup, integrate with dual-write path. Add integration tests for crash recovery. ~390 LOC. Depends on: D-core. Touches: src/ingester/mod.rs.","notes":"Depends on WAL core (cardinalsin-b9n). Follow-ups created: cardinalsin-am0 (recovery), cardinalsin-vla (flush+truncation), cardinalsin-3bm (config), cardinalsin-d6s (ack semantics).","status":"closed","priority":0,"issue_type":"feature","created_at":"2026-02-09T09:28:55.694823-07:00","created_by":"jeremyudis","updated_at":"2026-02-10T21:42:16.852973-07:00","closed_at":"2026-02-10T21:42:16.852973-07:00","close_reason":"WAL integrated into ingester write path with recovery and truncation","labels":["wal"],"dependencies":[{"issue_id":"cardinalsin-2q1","depends_on_id":"cardinalsin-b9n","type":"blocks","created_at":"2026-02-09T09:29:52.769009-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-306","title":"B1: Extract with_cas_retry helper from 9 copy-pasted retry loops in s3.rs","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-08T22:14:23.024521-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T15:36:32.20702-07:00","closed_at":"2026-02-16T15:36:32.20702-07:00","close_reason":"Extracted cas_retry! macro, refactored all 9 loops. PR #19"}
{"id":"cardinalsin-307","title":"tmp-lock-check","description":"temp","status":"tombstone","priority":2,"issue_type":"task","created_at":"2026-02-16T16:31:35.866691-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:31:46.346086-07:00","deleted_at":"2026-02-16T16:31:46.346086-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"task"}
{"id":"cardinalsin-308","title":"P1: Ingestion/Query Protocol Completeness","description":"Bring advertised protocol surface to functional completeness: OTLP gRPC, Arrow Flight ingest, and Flight SQL query service, with end-to-end verification.","notes":"Coordinator claim on 2026-02-17: parent epic claimed for parallel execution. Agent topology: A=308.1+308.2 (merged due shared runtime/API file overlap), B=308.3, C=308.4.","status":"in_progress","priority":1,"issue_type":"epic","assignee":"jeremyudis","created_at":"2026-02-16T16:32:00.519138-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T18:31:46.495774-07:00","external_ref":"gh-24"}
{"id":"cardinalsin-308.1","title":"Wire real gRPC servers for OTLP ingest and Flight SQL","description":"Binaries expose grpc_port and deploy maps protocol ports, but only HTTP servers are started. Stand up tonic servers and integrate lifecycle/shutdown for OTLP and Flight services.","notes":"Assigned to merged Agent A with cardinalsin-308.2 due shared runtime/API touchpoints (service wiring + flight ingest).","status":"in_progress","priority":1,"issue_type":"feature","assignee":"jeremyudis","created_at":"2026-02-16T16:32:03.826168-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T18:31:56.726495-07:00","external_ref":"gh-25","dependencies":[{"issue_id":"cardinalsin-308.1","depends_on_id":"cardinalsin-308","type":"parent-child","created_at":"2026-02-16T16:32:06.155759-07:00","created_by":"import"}]}
{"id":"cardinalsin-308.2","title":"Implement FlightIngestService decode path (currently no-op)","description":"src/api/ingest/flight_ingest.rs decode_batch currently returns Ok(None), dropping DoPut payloads. Implement IPC decode plus ingest flow with schema handling and robust error propagation.","notes":"Assigned to merged Agent A with cardinalsin-308.1 due shared runtime/API touchpoints (service wiring + flight ingest).","status":"in_progress","priority":1,"issue_type":"feature","assignee":"jeremyudis","created_at":"2026-02-16T16:32:06.839223-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T18:32:06.937433-07:00","external_ref":"gh-26","dependencies":[{"issue_id":"cardinalsin-308.2","depends_on_id":"cardinalsin-308","type":"parent-child","created_at":"2026-02-16T16:32:09.013482-07:00","created_by":"import"}]}
{"id":"cardinalsin-308.3","title":"Add protocol integration tests for OTLP and Flight paths","description":"Create integration/e2e coverage that validates OTLP and Flight ingest/query against running services (docker/minio profile) and catches regressions in protocol handlers.","notes":"Assigned to Agent B (integration tests), staged after Agent A API stabilization.","status":"in_progress","priority":1,"issue_type":"task","assignee":"jeremyudis","created_at":"2026-02-16T16:32:09.6939-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T18:32:17.181618-07:00","external_ref":"gh-27","dependencies":[{"issue_id":"cardinalsin-308.3","depends_on_id":"cardinalsin-308","type":"parent-child","created_at":"2026-02-16T16:32:11.813143-07:00","created_by":"import"}]}
{"id":"cardinalsin-308.4","title":"Reconcile docs/deploy port contracts with running services","description":"README and deploy mappings advertise interfaces not fully active today. Update docs/contracts or runtime wiring so published API surface is accurate and testable.","notes":"Assigned to Agent C (docs/deploy contract reconciliation), low conflict stream.","status":"in_progress","priority":2,"issue_type":"task","assignee":"jeremyudis","created_at":"2026-02-16T16:32:13.0751-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T18:33:36.504166-07:00","external_ref":"gh-38","dependencies":[{"issue_id":"cardinalsin-308.4","depends_on_id":"cardinalsin-308","type":"parent-child","created_at":"2026-02-16T16:32:15.229086-07:00","created_by":"import"}]}
{"id":"cardinalsin-309","title":"P1: Query Path Correctness and End-to-End Verifiability","description":"Make QueryNode::query reliably usable in end-to-end scenarios by fixing table model/object-store path handling and adding deterministic integration tests.","notes":"Coordinator claim on 2026-02-18: parent epic claimed for parallel execution. Agent topology: A=309.1+309.2 (merged due shared QueryNode/table-model/object-store path overlap), B=3ih+exk+s6s (merged due heavy overlap across integration/unit test files).\nAll child issues closed. Verified prerequisite merged PRs (#52 for 309.1/309.2 and #53 for 3ih/exk/s6s) before continuing. Additional validation completed in worktree fix/309-c-validation.","status":"closed","priority":1,"issue_type":"epic","assignee":"jeremyudis","created_at":"2026-02-16T16:32:16.088236-07:00","created_by":"jeremyudis","updated_at":"2026-02-19T11:52:21.131295-07:00","closed_at":"2026-02-19T11:52:21.131298-07:00","external_ref":"gh-28"}
{"id":"cardinalsin-309.1","title":"Fix QueryNode chunk registration and table model mismatch","description":"Current integration tests explicitly avoid QueryNode::query because table/object-store URL assumptions do not hold in normal test setups. Define and implement a consistent model (metrics abstraction vs per-chunk tables) and correct URL mapping.","notes":"Assigned to merged Agent A with sibling issue due shared QueryNode/table-model/object-store path changes and tight implementation-test coupling.\nCompleted in worktree fix/309-c-validation: normalized chunk URL mapping to configured bucket, added logical metrics table registration, and added query planning bootstrap fallback for missing metrics table.","status":"closed","priority":1,"issue_type":"bug","assignee":"jeremyudis","created_at":"2026-02-16T16:32:19.140328-07:00","created_by":"jeremyudis","updated_at":"2026-02-18T22:45:36.540444-07:00","closed_at":"2026-02-18T22:45:36.540448-07:00","external_ref":"gh-29","dependencies":[{"issue_id":"cardinalsin-309.1","depends_on_id":"cardinalsin-309","type":"parent-child","created_at":"2026-02-16T16:32:21.386368-07:00","created_by":"import"}]}
{"id":"cardinalsin-309.2","title":"Add end-to-end QueryNode::query tests over flushed chunks","description":"Add integration tests that ingest and flush data, then query through QueryNode::query in both local-memory and S3-compatible setups; validate real query correctness beyond engine smoke tests.","notes":"Assigned to merged Agent A with sibling issue due shared QueryNode/table-model/object-store path changes and tight implementation-test coupling.\nCompleted in worktree fix/309-c-validation: replaced end_to_end query workaround with real QueryNode::query assertions and added LocalFileSystem-backed query pipeline coverage.","status":"closed","priority":1,"issue_type":"task","assignee":"jeremyudis","created_at":"2026-02-16T16:32:22.146729-07:00","created_by":"jeremyudis","updated_at":"2026-02-18T22:45:36.651324-07:00","closed_at":"2026-02-18T22:45:36.651327-07:00","external_ref":"gh-30","dependencies":[{"issue_id":"cardinalsin-309.2","depends_on_id":"cardinalsin-309","type":"parent-child","created_at":"2026-02-16T16:32:24.271772-07:00","created_by":"import"}]}
{"id":"cardinalsin-30j","title":"Compactor has no health endpoint but Kubernetes manifest expects /health on :8080","description":"src/bin/compactor.rs runs only a background loop and signal handling, with no HTTP listener. deploy/kubernetes/compactor.yaml configures an HTTP liveness probe to /health on port 8080, so pods will fail probe checks and restart.\n\nFix options:\n1) Add a minimal HTTP server to compactor with /health and /ready.\n2) Replace liveness strategy in manifest for a worker-style process.","status":"open","priority":1,"issue_type":"bug","created_at":"2026-02-21T14:12:30.215464-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T14:21:51.922924-07:00","external_ref":"gh-59"}
{"id":"cardinalsin-310","title":"P2: Compaction Lifecycle Feature Completion","description":"Complete compactor functionality advertised in docs/config by implementing missing downsampling behavior and validating long-term data lifecycle semantics.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-16T16:32:53.662473-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:43.498939-07:00","external_ref":"gh-39"}
{"id":"cardinalsin-310.1","title":"Implement downsampling pipeline used by downsample_after_days settings","description":"CompactorConfig includes downsample_after_days and downsample_resolution, but compactor cycle currently enforces retention only. Implement downsample job selection, aggregation/write path, and metadata registration.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-02-16T16:32:56.749666-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:45.311126-07:00","external_ref":"gh-40","dependencies":[{"issue_id":"cardinalsin-310.1","depends_on_id":"cardinalsin-310","type":"parent-child","created_at":"2026-02-16T16:32:58.981477-07:00","created_by":"import"}]}
{"id":"cardinalsin-310.2","title":"Add retention/downsampling lifecycle integration tests","description":"Add integration tests validating retention cutoff behavior plus downsample-before-delete semantics over realistic time windows to prevent lifecycle regressions.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-16T16:32:59.841871-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:46.645648-07:00","external_ref":"gh-41","dependencies":[{"issue_id":"cardinalsin-310.2","depends_on_id":"cardinalsin-310","type":"parent-child","created_at":"2026-02-16T16:33:02.145839-07:00","created_by":"import"}]}
{"id":"cardinalsin-311","title":"P1: Ingestion/Query Protocol Completeness","description":"Bring advertised protocol surface to functional completeness: OTLP gRPC, Arrow Flight ingest, and Flight SQL query service, with end-to-end verification.","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2026-02-16T16:35:25.326653-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.542397-07:00","deleted_at":"2026-02-16T16:42:15.542397-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"epic"}
{"id":"cardinalsin-311.1","title":"Wire real gRPC servers for OTLP ingest and Flight SQL","description":"Binaries expose grpc_port and deploy maps protocol ports, but only HTTP servers are started. Stand up tonic servers and integrate lifecycle/shutdown for OTLP + Flight services.","status":"tombstone","priority":1,"issue_type":"feature","created_at":"2026-02-16T16:35:25.410444-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.5424-07:00","deleted_at":"2026-02-16T16:42:15.5424-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"feature"}
{"id":"cardinalsin-311.2","title":"Implement FlightIngestService decode path (currently no-op)","description":"src/api/ingest/flight_ingest.rs decode_batch currently returns Ok(None), dropping DoPut payloads. Implement IPC decode + ingest flow with schema handling and errors.","status":"tombstone","priority":1,"issue_type":"feature","created_at":"2026-02-16T16:35:25.498136-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.5424-07:00","deleted_at":"2026-02-16T16:42:15.5424-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"feature"}
{"id":"cardinalsin-311.3","title":"Add protocol integration tests for OTLP and Flight paths","description":"Create integration/e2e coverage that validates OTLP and Flight ingest/query against running services (docker/minio profile) and catches regressions in protocol handlers.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2026-02-16T16:35:25.586776-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.542401-07:00","deleted_at":"2026-02-16T16:42:15.542401-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"task"}
{"id":"cardinalsin-311.4","title":"Reconcile docs/deploy port contracts with running services","description":"README and deploy mappings advertise interfaces not fully active today. Update docs/contracts or runtime wiring so published API surface is accurate and testable.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2026-02-16T16:35:25.667893-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.542402-07:00","deleted_at":"2026-02-16T16:42:15.542402-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"task"}
{"id":"cardinalsin-312","title":"P1: Query Path Correctness and End-to-End Verifiability","description":"Make QueryNode::query reliably usable in real end-to-end scenarios by fixing table model/object-store path handling and adding deterministic integration tests.","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2026-02-16T16:35:25.75299-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.542404-07:00","deleted_at":"2026-02-16T16:42:15.542404-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"epic"}
{"id":"cardinalsin-312.1","title":"Fix QueryNode chunk registration and table model mismatch","description":"Current integration tests explicitly avoid query_node.query() due table/object-store URL assumptions. Define and implement a consistent model (metrics abstraction vs per-chunk tables) and correct URL mapping.","status":"tombstone","priority":1,"issue_type":"bug","created_at":"2026-02-16T16:35:25.833958-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.542406-07:00","deleted_at":"2026-02-16T16:42:15.542406-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"bug"}
{"id":"cardinalsin-312.2","title":"Add end-to-end QueryNode::query tests over flushed chunks","description":"Add integration tests that ingest+flush then query through QueryNode::query in both local-memory and S3-compatible setups; validate real query correctness rather than engine smoke queries.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2026-02-16T16:35:25.915367-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.542407-07:00","deleted_at":"2026-02-16T16:42:15.542407-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"task"}
{"id":"cardinalsin-3bm","title":"D-core: WAL config/env plumbing","description":"Wire WAL config to environment/config: WAL_ENABLED, WAL_DIR, WAL_SYNC_MODE, WAL_MAX_SEGMENT_SIZE. Document defaults.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-10T00:09:34.40873-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T00:25:29.570739-07:00","closed_at":"2026-02-12T00:25:29.570739-07:00","close_reason":"WAL env vars wired: WAL_ENABLED, WAL_DIR, WAL_SYNC_MODE, WAL_MAX_SEGMENT_SIZE"}
{"id":"cardinalsin-3ih","title":"E10: Fix initialization-only and println-only tests","description":"3 tests only verify initialization (e.g. Arc::strong_count >= 1). Several tests only println! results without assertions. Add real assertions that verify behavior. ~250 LOC. Touches: tests/adaptive_indexing_tests.rs, others.","notes":"Assigned to merged Agent B with sibling test-hardening issues due high probability of touching the same test modules and assertion blocks.\nCompleted in worktree fix/309-c-validation: replaced initialization-only assertions in adaptive indexing tests with executable query/assert behavior checks.","status":"closed","priority":1,"issue_type":"bug","assignee":"jeremyudis","created_at":"2026-02-09T09:29:14.74649-07:00","created_by":"jeremyudis","updated_at":"2026-02-18T22:45:36.756889-07:00","closed_at":"2026-02-18T22:45:36.756893-07:00","external_ref":"gh-31","dependencies":[{"issue_id":"cardinalsin-3ih","depends_on_id":"cardinalsin-309","type":"parent-child","created_at":"2026-02-16T16:32:31.148175-07:00","created_by":"import"}]}
{"id":"cardinalsin-4tn","title":"E6: Query chunk pinning / extend GC grace period","description":"Long queries fail with S3 NotFound if compaction GC deletes chunks during execution. Current 60s grace too short. Implement chunk pinning (~200 LOC) or extend grace to 5-10 min as interim. Depends on: E1-E5 compaction leasing.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-09T09:29:05.206566-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T09:42:11.491164-07:00","closed_at":"2026-02-12T09:42:11.491164-07:00","close_reason":"PR #8 - chunk pin registry + GC grace period extended to 5min","dependencies":[{"issue_id":"cardinalsin-4tn","depends_on_id":"cardinalsin-iry","type":"blocks","created_at":"2026-02-09T09:29:52.862668-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-5sv","title":"C-tooling: AtomicJsonStore<T> generic extraction + migration tool + tests","description":"After catalog core is done: Extract AtomicJsonStore<T> to reduce s3.rs by ~60%. Build migrate-metadata binary for format migration. Add tests for single-file atomicity. ~450 LOC. Depends on: Phase C core and B1 (retry extraction).","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-09T09:28:48.655081-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:15.365572-07:00","external_ref":"gh-32","dependencies":[{"issue_id":"cardinalsin-5sv","depends_on_id":"cardinalsin-xjy","type":"blocks","created_at":"2026-02-09T09:29:52.586872-07:00","created_by":"jeremyudis"},{"issue_id":"cardinalsin-5sv","depends_on_id":"cardinalsin-306","type":"blocks","created_at":"2026-02-09T09:29:52.682305-07:00","created_by":"jeremyudis"},{"issue_id":"cardinalsin-5sv","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:32:31.149682-07:00","created_by":"import"}]}
{"id":"cardinalsin-69s","title":"F1: Shard split crash safety - persistent state machine","description":"Split failure leaves system in unrecoverable state. Add persistent state machine that tracks phase progress and can resume from any point. ~400 LOC. Depends on: Phase C (metadata merge simplifies state persistence). Touches: src/sharding/splitter.rs.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-02-09T09:29:23.941882-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T15:07:39.952318-07:00","closed_at":"2026-02-12T15:07:39.952318-07:00","close_reason":"Persistent state machine with SplitProgress tracking all 5 phases + cutover fencing. PR #17.","dependencies":[{"issue_id":"cardinalsin-69s","depends_on_id":"cardinalsin-xjy","type":"blocks","created_at":"2026-02-09T09:29:52.952835-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-6kp","title":"Fix docker-compose Grafana provisioning contract (missing repo assets)","description":"deploy/docker-compose.yml mounts deploy/grafana/provisioning into Grafana, but this directory is missing from the repository.\n\nScope:\n- Either add provisioning assets (datasource + dashboard definitions), or remove the mount and document manual setup.\n- Ensure README and compose behavior are consistent.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-21T14:13:10.122759-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T14:21:46.921037-07:00","external_ref":"gh-61"}
{"id":"cardinalsin-87x","title":"B10: Fix from_sql case-sensitivity in streaming predicates","description":"src/query/streaming.rs from_sql lowercases string predicate values, breaking case-sensitive queries. Fix: don't lowercase values, only lowercase column names. ~10 LOC.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T09:28:37.573267-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T00:28:29.108964-07:00","closed_at":"2026-02-12T00:28:29.108964-07:00","close_reason":"No bug found - values already case-sensitive. Added PartialEq + 2 regression tests."}
{"id":"cardinalsin-88u","title":"B4: Migrate error.rs to thiserror, fix serde_json error chain loss","description":"Replace hand-rolled Display/Error impls with thiserror derive macros. Fix From<serde_json::Error> losing type info. Resolve ShardError/ShardNotFound redundancy. ~110 LOC changed. Touches: src/error.rs and all files matching on Error variants.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-09T09:28:29.663964-07:00","created_by":"jeremyudis","updated_at":"2026-02-10T10:30:07.631923-07:00","closed_at":"2026-02-10T10:30:07.631923-07:00","close_reason":"Migrated error.rs to thiserror derives. 58 lines of boilerplate removed (157->99 LOC). Fixed ShardError Display, removed redundant ShardError::NotFound. All 68 lib tests pass."}
{"id":"cardinalsin-8tt","title":"F7: Shard router generation validation","description":"ShardRouter::get_shard() only uses TTL-based cache expiry, no generation validation. Stale entries route writes to split shards. Add generation check. ~50 LOC. Touches: src/sharding/router.rs.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T09:29:39.018881-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T10:32:39.293893-07:00","closed_at":"2026-02-12T10:32:39.293893-07:00","close_reason":"PR #12 - generation validation + active-state check in ShardRouter"}
{"id":"cardinalsin-9lt","title":"B3: Add complete_compaction target chunk validation guard","notes":"PR review confirmed: complete_compaction silently does nothing if target chunk not in catalog. Need validation guard.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-08T22:14:23.28182-07:00","created_by":"jeremyudis","updated_at":"2026-02-10T21:07:44.853754-07:00","closed_at":"2026-02-10T21:07:44.853754-07:00","close_reason":"P0-P1 fixes applied: WAL crash-tolerant recovery, WAL init warning, PutMode::Create for first write, complete_compaction target validation"}
{"id":"cardinalsin-9y6","title":"F6: Fix CachedObjectStore metadata fabrication","description":"CachedObjectStore::get fabricates ObjectMeta with current timestamp instead of real metadata. Breaks ETag-based caching. ~30 LOC. Touches: src/query/cache.rs.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-02-09T09:29:37.046133-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T14:51:55.402268-07:00","closed_at":"2026-02-12T14:51:55.402268-07:00","close_reason":"Fixed metadata fabrication via OnceLock side-channel. PR #13."}
{"id":"cardinalsin-am0","title":"D-core: WAL recovery + replay into buffer","description":"Implement WAL recovery at ingester startup: open WAL, read entries after last flushed seq, append to buffer, handle CRC/truncation cases, and truncate already-flushed segments.","status":"closed","priority":0,"issue_type":"feature","created_at":"2026-02-10T00:09:24.139142-07:00","created_by":"jeremyudis","updated_at":"2026-02-10T21:42:16.981928-07:00","closed_at":"2026-02-10T21:42:16.981928-07:00","close_reason":"Recovery implemented in ensure_wal() - replays entries after last flushed seq"}
{"id":"cardinalsin-b34","title":"P0: Reliability and Correctness Hardening","description":"Close production correctness gaps uncovered by current tests and runtime behavior: WAL durability activation, shard split correctness, deterministic routing behavior, and metadata freshness across nodes. This epic is the near-term release gate.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-02-16T16:26:29.380473-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:04.79547-07:00","external_ref":"gh-21"}
{"id":"cardinalsin-b34.1","title":"Boot WAL in binaries and fail fast if durability cannot initialize","description":"Ingester defaults WAL to enabled but binaries never call ensure_wal(), so write durability is silently disabled. Wire async WAL init into startup before serving traffic, fail fast (or explicit opt-out) on init failure, and add startup logs/health checks for WAL state.","status":"closed","priority":0,"issue_type":"bug","created_at":"2026-02-16T16:26:39.643883-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T18:17:27.597783-07:00","closed_at":"2026-02-16T18:17:27.597783-07:00","close_reason":"WAL initialization is now wired into binaries with fail-fast startup behavior, explicit opt-out, and readiness signaling/tests.","external_ref":"gh-22","dependencies":[{"issue_id":"cardinalsin-b34.1","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:26:39.64725-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-b34.2","title":"Fix shard split Phase 4 cutover path mismatch in tests and invariants","description":"cargo test currently fails at tests/shard_split_tests.rs:208 with ShardNotFound('test-shard-1'). Align cutover preconditions with test setup, enforce clear invariants in code, and add regression coverage so phase-4 behavior is deterministic.","status":"in_progress","priority":0,"issue_type":"bug","assignee":"jeremyudis","created_at":"2026-02-16T16:31:49.69201-07:00","created_by":"jeremyudis","updated_at":"2026-02-17T23:04:02.469999-07:00","external_ref":"gh-23","dependencies":[{"issue_id":"cardinalsin-b34.2","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:31:52.01986-07:00","created_by":"import"}]}
{"id":"cardinalsin-b34.3","title":"Remove 300s test sleep from shard split full-flow tests","description":"test_full_split_execution currently spends about 300 seconds in cleanup grace period. Inject configurable grace period/time provider so tests complete in milliseconds while production retains safety windows.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T16:31:52.901668-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:17.115281-07:00","external_ref":"gh-33","dependencies":[{"issue_id":"cardinalsin-b34.3","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:31:55.151967-07:00","created_by":"import"}]}
{"id":"cardinalsin-b34.4","title":"Add cross-node metadata freshness mode for catalog cache","description":"S3 catalog cache currently relies on local TTL invalidation only. Add ETag revalidation or bypass mode for freshness-critical query paths to avoid stale reads across nodes after recent writes.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-16T16:31:57.479185-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:17.116044-07:00","external_ref":"gh-34","dependencies":[{"issue_id":"cardinalsin-b34.4","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:31:59.743453-07:00","created_by":"import"}]}
{"id":"cardinalsin-b34.5","title":"Fix shard split Phase 4 cutover path mismatch in tests and invariants","description":"\nrunning 68 tests\ntest adaptive_index::column_promoter::tests::test_progress_percentage ... ok\ntest adaptive_index::recommender::tests::test_index_type_selection ... ok\ntest adaptive_index::recommender::tests::test_recommendations ... ok\ntest adaptive_index::column_promoter::tests::test_promote_column ... ok\ntest adaptive_index::lifecycle::tests::test_promote_to_visible ... ok\ntest adaptive_index::lifecycle::tests::test_create_invisible_index ... ok\ntest cluster::node_registry::tests::test_heartbeat ... ok\ntest api::query::flight_sql::tests::test_prepared_statement ... ok\ntest adaptive_index::stats_collector::tests::test_record_filter ... ok\ntest cluster::query_router::tests::test_query_routing ... ok\ntest cluster::node_registry::tests::test_node_registration ... ok\ntest cluster::node_registry::tests::test_shard_filtering ... ok\ntest api::ingest::prometheus::tests::test_convert_prom_to_arrow ... ok\ntest api::ingest::otlp::tests::test_data_points_to_arrow ... ok\ntest compactor::levels::tests::test_level_conversion ... ok\ntest adaptive_index::stats_collector::tests::test_percentile_calculation ... ok\ntest compactor::levels::tests::test_level_from ... ok\ntest compactor::levels::tests::test_level_next ... ok\ntest cluster::query_router::tests::test_targeted_fanout ... ok\ntest cluster::shard_assignment::tests::test_consistent_hash_stability ... ok\ntest cluster::shard_assignment::tests::test_consistent_hash_ring ... ok\ntest cluster::write_router::tests::test_write_routing ... ok\ntest ingester::broadcast::tests::test_broadcast ... ok\ntest ingester::broadcast::tests::test_no_subscribers ... ok\ntest ingester::buffer::tests::test_buffer_clear ... ok\ntest ingester::buffer::tests::test_buffer_append ... ok\ntest ingester::buffer::tests::test_buffer_take ... ok\ntest ingester::topic_broadcast::tests::test_filter_builder ... ok\ntest ingester::topic_broadcast::tests::test_topic_filter_matching ... ok\ntest api::ingest::flight_ingest::tests::test_batch_to_flight_data ... ok\ntest ingester::wal::tests::test_crc_roundtrip ... ok\ntest ingester::wal::tests::test_rotation ... ok\ntest ingester::wal::tests::test_corruption_detection ... ok\ntest metadata::local::tests::test_delete_chunk ... ok\ntest metadata::local::tests::test_register_and_get_chunk ... ok\ntest metadata::predicates::tests::test_and_predicate ... ok\ntest metadata::local::tests::test_time_range_query ... ok\ntest metadata::predicates::tests::test_between_predicate ... ok\ntest metadata::predicates::tests::test_eq_predicate_pruning ... ok\ntest metadata::predicates::tests::test_gt_predicate_pruning ... ok\ntest metadata::predicates::tests::test_in_predicate ... ok\ntest metadata::predicates::tests::test_lt_predicate_pruning ... ok\ntest ingester::wal::tests::test_truncation ... ok\ntest query::cache::tests::test_cache_hit_l1 ... ok\ntest query::cache::tests::test_cache_hit_l2 ... ok\ntest query::cache::tests::test_cache_miss_fetch ... ok\ntest query::engine::tests::test_path_to_table_name ... ok\ntest query::router::tests::test_router_invalidation ... ok\ntest query::router::tests::test_router_caching ... ok\ntest ingester::parquet_writer::tests::test_compression_ratio ... ok\ntest schema::metrics::tests::test_cardinality_classification ... ok\ntest schema::metrics::tests::test_custom_schema ... ok\ntest schema::metrics::tests::test_default_schema ... ok\ntest schema::metrics::tests::test_dictionary_encoding ... ok\ntest query::streaming::tests::test_empty_filter ... ok\ntest sharding::monitor::tests::test_rolling_average ... ok\ntest query::streaming::tests::test_query_filter_parsing ... ok\ntest sharding::router::tests::test_invalidation ... ok\ntest sharding::rebalancer::tests::test_lease_transfer ... ok\ntest sharding::router::tests::test_routing ... ok\ntest sharding::splitter::tests::test_split_point_calculation ... ok\ntest sharding::splitter::tests::test_split_shard ... ok\ntest query::engine::tests::test_engine_creation ... ok\ntest ingester::parquet_writer::tests::test_write_batch ... ok\ntest compactor::merge::tests::test_sort_batch ... ok\ntest compactor::merge::tests::test_merge_chunks ... ok\ntest sharding::monitor::tests::test_hot_shard_detection ... ok\ntest ingester::topic_broadcast::tests::test_filtered_broadcast ... ok\n\ntest result: ok. 68 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.07s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 12 tests\ntest test_extract_filter_columns_simple ... ok\ntest test_index_usage_tracking ... ok\ntest test_index_removal ... ok\ntest test_groupby_statistics_collection ... ok\ntest test_filter_statistics_collection ... ok\ntest test_index_recommendation_generation ... ok\ntest test_query_filter_parsing ... ok\ntest test_query_node_integration ... ok\ntest test_graceful_degradation_without_indexes ... ok\ntest test_index_aware_query_usage ... ok\ntest test_invisible_index_promotion ... ok\ntest test_full_index_lifecycle ... ok\n\ntest result: ok. 12 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.17s\n\n\nrunning 5 tests\ntest test_atomic_compaction_completion ... ok\ntest test_atomic_retry_on_conflict ... ok\ntest test_concurrent_chunk_registration ... ok\ntest test_concurrent_compactions ... ok\ntest test_heavy_concurrent_load ... ok\n\ntest result: ok. 5 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 1.48s\n\n\nrunning 14 tests\ntest test_node_heartbeat_and_failure_detection ... ok\ntest test_mixed_node_types ... ok\ntest test_load_balancing ... ok\ntest test_node_registration_and_discovery ... ok\ntest test_query_fanout ... ok\ntest test_shard_assignment_load_based ... ok\ntest test_node_drain_and_removal ... ok\ntest test_query_targeted_fanout ... ok\ntest test_write_routing_with_node_failure ... ok\ntest test_write_routing ... ok\ntest test_shard_assignment_consistent_hash ... ok\ntest test_shard_rebalancing ... ok\ntest test_cluster_scale_in ... ok\ntest test_cluster_scale_out ... ok\n\ntest result: ok. 14 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s\n\n\nrunning 33 tests\ntest test_chunk_merger_empty_paths ... ok\ntest test_complete_split_on_nonexistent_shard ... ok\ntest test_compaction_job_failed_status ... ok\ntest test_chunk_merger_nonexistent_chunk ... ok\ntest test_error_from_io ... ok\ntest test_error_from_arrow ... ok\ntest test_compactor_backpressure_initial_state ... ok\ntest test_error_from_serde_json ... ok\ntest test_compaction_level_tracking_through_metadata ... ok\ntest test_level_enum_values ... ok\ntest test_multiple_compaction_jobs ... ok\ntest test_concurrent_split_and_chunk_registration ... ok\ntest test_parquet_writer_empty_batches_slice ... ok\ntest test_ingester_buffer_stats_accuracy ... ok\ntest test_buffer_full_rejection ... ok\ntest test_buffer_full_after_accumulation ... ok\ntest test_s3_shard_not_found ... ok\ntest test_shard_monitor_cool_shard ... ok\ntest test_s3_shard_metadata_lifecycle ... ok\ntest test_shard_monitor_cpu_recording ... ok\ntest test_shard_monitor_metrics_after_writes ... ok\ntest test_shard_monitor_metrics_retrieval ... ok\ntest test_shard_monitor_no_data ... ok\ntest test_s3_split_lifecycle ... ok\ntest test_split_full_lifecycle ... ok\ntest test_split_progress_on_nonexistent_shard ... ok\ntest test_time_index_rebuild ... ok\ntest test_ingester_topic_broadcast_on_flush ... ok\ntest test_ingester_broadcast_on_flush ... ok\ntest test_multiple_flush_cycles ... ok\ntest test_parquet_writer_multiple_batches_roundtrip ... ok\ntest test_write_flush_verify_roundtrip ... ok\ntest test_ingester_no_broadcast_without_flush ... ok\n\ntest result: ok. 33 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.12s\n\n\nrunning 22 tests\ntest e2e::smoke::health_tests::test_all_services_healthy ... ignored, requires running docker-compose stack\ntest e2e::smoke::health_tests::test_ingester_health_returns_ok ... ignored, requires running docker-compose stack\ntest e2e::smoke::health_tests::test_ingester_ready ... ignored, requires running docker-compose stack\ntest e2e::smoke::health_tests::test_query_health_returns_ok ... ignored, requires running docker-compose stack\ntest e2e::smoke::health_tests::test_query_ready ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_instant_query ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_label_values_endpoint ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_labels_endpoint ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_query_with_labels ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_range_query ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_response_format ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_sum_aggregation ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_sum_by_aggregation ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_invalid_sql_returns_error ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_multiple_metrics_queryable ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_sql_aggregation_query ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_sql_query_with_filters ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_time_range_query ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_write_then_query_returns_data ... ignored, requires running docker-compose stack\ntest e2e::harness::tests::test_generate_cpu_samples ... ok\ntest e2e::harness::tests::test_sample_builder ... ok\ntest e2e::harness::tests::test_generate_test_samples ... ok\n\ntest result: ok. 3 passed; 0 failed; 19 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 7 tests\ntest test_complete_cluster_pipeline ... ok\ntest test_distributed_write_routing ... ok\ntest test_cost_optimization_full_stack ... ok\ntest test_ingestion_with_predicate_pushdown ... ok\ntest test_multi_tenant_isolation ... ok\ntest test_streaming_with_topic_filtering ... ok\ntest test_complete_query_pipeline ... ok\n\ntest result: ok. 7 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.10s\n\n\nrunning 32 tests\ntest test_error_source_chain ... ok\ntest test_error_display_formats ... ok\ntest test_get_chunks_for_nonexistent_shard ... ok\ntest test_compaction_job_lifecycle ... ok\ntest test_cas_stale_generation_error_format ... ok\ntest test_cas_max_generation_values ... ok\ntest test_delete_nonexistent_chunk ... ok\ntest test_get_nonexistent_chunk ... ok\ntest test_level_candidates_nonexistent_level ... ok\ntest test_list_chunks_uninitialized_metadata ... ok\ntest test_get_chunks_empty_time_range ... ok\ntest test_compaction_with_single_source ... ok\ntest test_l0_candidates_empty ... ok\ntest test_register_chunk_with_zero_timestamps ... ok\ntest test_split_state_nonexistent_shard ... ok\ntest test_register_duplicate_chunk_path ... ok\ntest test_timerange_from_range ... ok\ntest test_timerange_contains_exact_boundaries ... ok\ntest test_timerange_negative_timestamps ... ok\ntest test_timerange_overlaps_adjacent ... ok\ntest test_timerange_overlaps_disjoint ... ok\ntest test_timerange_overlaps_subset ... ok\ntest test_timerange_single_point ... ok\ntest test_timerange_zero_timestamps ... ok\ntest test_write_buffer_empty_operations ... ok\ntest test_write_buffer_size_tracking ... ok\ntest test_write_buffer_multiple_takes ... ok\ntest test_concurrent_registration_data_integrity ... ok\ntest test_ingester_buffer_below_threshold_no_flush ... ok\ntest test_metadata_cas_fails_loudly_when_unsafe_overwrite_disabled ... ok\ntest test_metadata_cas_fallback_overwrite_when_enabled ... ok\ntest test_ingester_flush_produces_valid_parquet ... ok\n\ntest result: ok. 32 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.04s\n\n\nrunning 9 tests\ntest test_new_shard_creation ... ok\ntest test_retry_with_backoff ... ok\ntest test_generation_increments ... ok\ntest test_cas_prevents_lost_updates ... ok\ntest test_cas_with_state_transitions ... ok\ntest test_independent_shard_updates ... ok\ntest test_nonexistent_shard ... ok\ntest test_concurrent_cas_updates ... ok\ntest test_stale_generation_rejected ... ok\n\ntest result: ok. 9 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 5 tests\ntest test_new_chunks_start_at_l0 ... ok\ntest test_level_filtering ... ok\ntest test_l0_to_l1_progression ... ok\ntest test_l1_to_l2_progression ... ok\ntest test_full_level_progression ... ok\n\ntest result: ok. 5 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s\n\n\nrunning 7 tests\ntest test_predicate_pushdown_between ... ok\ntest test_empty_result_optimization ... ok\ntest test_predicate_pushdown_with_ranges ... ok\ntest test_predicate_pushdown_with_and_or ... ok\ntest test_predicate_pushdown_with_in_list ... ok\ntest test_predicate_pushdown_reduces_chunks ... ok\ntest test_cost_reduction_simulation ... ok\n\ntest result: ok. 7 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.24s\n\n\nrunning 8 tests\ntest test_phase1_preparation ... ok\ntest test_split_point_calculation ... ok\ntest test_phase2_dualwrite_state ... ok\ntest test_phase4_cutover ... FAILED\ntest test_phase3_backfill ... ok\ntest test_backfill_progress_tracking ... ok\ntest test_phase5_cleanup ... ok\ntest test_full_split_execution has been running for over 60 seconds\ntest test_full_split_execution ... ok\n\nfailures:\n\n---- test_phase4_cutover stdout ----\n\nthread 'test_phase4_cutover' (3752473) panicked at tests/shard_split_tests.rs:208:45:\ncalled `Result::unwrap()` on an `Err` value: ShardNotFound(\"test-shard-1\")\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n\n\nfailures:\n    test_phase4_cutover\n\ntest result: FAILED. 7 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 310.01s currently fails at tests/shard_split_tests.rs:208 with ShardNotFound(\"test-shard-1\"). Align cutover preconditions with test setup, enforce clear invariants in code, and add regression coverage so phase-4 behavior is deterministic.","status":"tombstone","priority":0,"issue_type":"bug","created_at":"2026-02-16T16:33:41.38106-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:17.838049-07:00","dependencies":[{"issue_id":"cardinalsin-b34.5","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:33:43.667939-07:00","created_by":"import"}],"deleted_at":"2026-02-16T16:42:18.838049-07:00"}
{"id":"cardinalsin-b34.6","title":"Fix shard split Phase 4 cutover path mismatch in tests and invariants","description":"\nrunning 68 tests\ntest adaptive_index::column_promoter::tests::test_progress_percentage ... ok\ntest adaptive_index::recommender::tests::test_index_type_selection ... ok\ntest adaptive_index::recommender::tests::test_recommendations ... ok\ntest adaptive_index::column_promoter::tests::test_promote_column ... ok\ntest adaptive_index::lifecycle::tests::test_create_invisible_index ... ok\ntest adaptive_index::lifecycle::tests::test_promote_to_visible ... ok\ntest api::query::flight_sql::tests::test_prepared_statement ... ok\ntest cluster::node_registry::tests::test_heartbeat ... ok\ntest cluster::query_router::tests::test_query_routing ... ok\ntest adaptive_index::stats_collector::tests::test_record_filter ... ok\ntest api::ingest::prometheus::tests::test_convert_prom_to_arrow ... ok\ntest api::ingest::otlp::tests::test_data_points_to_arrow ... ok\ntest cluster::node_registry::tests::test_node_registration ... ok\ntest compactor::levels::tests::test_level_conversion ... ok\ntest compactor::levels::tests::test_level_from ... ok\ntest compactor::levels::tests::test_level_next ... ok\ntest cluster::node_registry::tests::test_shard_filtering ... ok\ntest adaptive_index::stats_collector::tests::test_percentile_calculation ... ok\ntest cluster::write_router::tests::test_write_routing ... ok\ntest cluster::query_router::tests::test_targeted_fanout ... ok\ntest cluster::shard_assignment::tests::test_consistent_hash_stability ... ok\ntest cluster::shard_assignment::tests::test_consistent_hash_ring ... ok\ntest ingester::broadcast::tests::test_broadcast ... ok\ntest ingester::broadcast::tests::test_no_subscribers ... ok\ntest ingester::buffer::tests::test_buffer_append ... ok\ntest ingester::buffer::tests::test_buffer_take ... ok\ntest ingester::buffer::tests::test_buffer_clear ... ok\ntest ingester::topic_broadcast::tests::test_filter_builder ... ok\ntest ingester::topic_broadcast::tests::test_topic_filter_matching ... ok\ntest api::ingest::flight_ingest::tests::test_batch_to_flight_data ... ok\ntest ingester::wal::tests::test_crc_roundtrip ... ok\ntest ingester::wal::tests::test_rotation ... ok\ntest ingester::wal::tests::test_corruption_detection ... ok\ntest metadata::local::tests::test_delete_chunk ... ok\ntest metadata::local::tests::test_register_and_get_chunk ... ok\ntest metadata::local::tests::test_time_range_query ... ok\ntest metadata::predicates::tests::test_and_predicate ... ok\ntest metadata::predicates::tests::test_between_predicate ... ok\ntest metadata::predicates::tests::test_eq_predicate_pruning ... ok\ntest metadata::predicates::tests::test_gt_predicate_pruning ... ok\ntest metadata::predicates::tests::test_in_predicate ... ok\ntest metadata::predicates::tests::test_lt_predicate_pruning ... ok\ntest ingester::wal::tests::test_truncation ... ok\ntest query::cache::tests::test_cache_hit_l1 ... ok\ntest query::cache::tests::test_cache_miss_fetch ... ok\ntest query::cache::tests::test_cache_hit_l2 ... ok\ntest query::engine::tests::test_path_to_table_name ... ok\ntest query::router::tests::test_router_invalidation ... ok\ntest query::router::tests::test_router_caching ... ok\ntest ingester::parquet_writer::tests::test_compression_ratio ... ok\ntest schema::metrics::tests::test_cardinality_classification ... ok\ntest schema::metrics::tests::test_custom_schema ... ok\ntest schema::metrics::tests::test_default_schema ... ok\ntest schema::metrics::tests::test_dictionary_encoding ... ok\ntest query::streaming::tests::test_empty_filter ... ok\ntest sharding::monitor::tests::test_rolling_average ... ok\ntest query::streaming::tests::test_query_filter_parsing ... ok\ntest sharding::router::tests::test_invalidation ... ok\ntest sharding::rebalancer::tests::test_lease_transfer ... ok\ntest sharding::router::tests::test_routing ... ok\ntest sharding::splitter::tests::test_split_point_calculation ... ok\ntest sharding::splitter::tests::test_split_shard ... ok\ntest query::engine::tests::test_engine_creation ... ok\ntest ingester::parquet_writer::tests::test_write_batch ... ok\ntest compactor::merge::tests::test_merge_chunks ... ok\ntest compactor::merge::tests::test_sort_batch ... ok\ntest sharding::monitor::tests::test_hot_shard_detection ... ok\ntest ingester::topic_broadcast::tests::test_filtered_broadcast ... ok\n\ntest result: ok. 68 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.07s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 12 tests\ntest test_extract_filter_columns_simple ... ok\ntest test_index_usage_tracking ... ok\ntest test_index_removal ... ok\ntest test_groupby_statistics_collection ... ok\ntest test_filter_statistics_collection ... ok\ntest test_index_recommendation_generation ... ok\ntest test_query_filter_parsing ... ok\ntest test_query_node_integration ... ok\ntest test_graceful_degradation_without_indexes ... ok\ntest test_index_aware_query_usage ... ok\ntest test_full_index_lifecycle ... ok\ntest test_invisible_index_promotion ... ok\n\ntest result: ok. 12 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.17s\n\n\nrunning 5 tests\ntest test_atomic_compaction_completion ... ok\ntest test_atomic_retry_on_conflict ... ok\ntest test_concurrent_chunk_registration ... ok\ntest test_concurrent_compactions ... ok\ntest test_heavy_concurrent_load ... ok\n\ntest result: ok. 5 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 1.51s\n\n\nrunning 14 tests\ntest test_node_registration_and_discovery ... ok\ntest test_node_heartbeat_and_failure_detection ... ok\ntest test_node_drain_and_removal ... ok\ntest test_mixed_node_types ... ok\ntest test_load_balancing ... ok\ntest test_query_fanout ... ok\ntest test_query_targeted_fanout ... ok\ntest test_shard_assignment_load_based ... ok\ntest test_write_routing ... ok\ntest test_write_routing_with_node_failure ... ok\ntest test_shard_assignment_consistent_hash ... ok\ntest test_cluster_scale_out ... ok\ntest test_shard_rebalancing ... ok\ntest test_cluster_scale_in ... ok\n\ntest result: ok. 14 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 33 tests\ntest test_chunk_merger_empty_paths ... ok\ntest test_chunk_merger_nonexistent_chunk ... ok\ntest test_error_from_arrow ... ok\ntest test_error_from_io ... ok\ntest test_complete_split_on_nonexistent_shard ... ok\ntest test_compaction_job_failed_status ... ok\ntest test_error_from_serde_json ... ok\ntest test_compactor_backpressure_initial_state ... ok\ntest test_compaction_level_tracking_through_metadata ... ok\ntest test_level_enum_values ... ok\ntest test_multiple_compaction_jobs ... ok\ntest test_concurrent_split_and_chunk_registration ... ok\ntest test_parquet_writer_empty_batches_slice ... ok\ntest test_ingester_buffer_stats_accuracy ... ok\ntest test_buffer_full_rejection ... ok\ntest test_buffer_full_after_accumulation ... ok\ntest test_s3_shard_not_found ... ok\ntest test_s3_shard_metadata_lifecycle ... ok\ntest test_shard_monitor_cool_shard ... ok\ntest test_shard_monitor_cpu_recording ... ok\ntest test_s3_split_lifecycle ... ok\ntest test_shard_monitor_metrics_after_writes ... ok\ntest test_shard_monitor_metrics_retrieval ... ok\ntest test_shard_monitor_no_data ... ok\ntest test_split_full_lifecycle ... ok\ntest test_split_progress_on_nonexistent_shard ... ok\ntest test_time_index_rebuild ... ok\ntest test_ingester_topic_broadcast_on_flush ... ok\ntest test_ingester_broadcast_on_flush ... ok\ntest test_multiple_flush_cycles ... ok\ntest test_parquet_writer_multiple_batches_roundtrip ... ok\ntest test_write_flush_verify_roundtrip ... ok\ntest test_ingester_no_broadcast_without_flush ... ok\n\ntest result: ok. 33 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.11s\n\n\nrunning 22 tests\ntest e2e::smoke::health_tests::test_all_services_healthy ... ignored, requires running docker-compose stack\ntest e2e::smoke::health_tests::test_ingester_health_returns_ok ... ignored, requires running docker-compose stack\ntest e2e::smoke::health_tests::test_ingester_ready ... ignored, requires running docker-compose stack\ntest e2e::smoke::health_tests::test_query_health_returns_ok ... ignored, requires running docker-compose stack\ntest e2e::smoke::health_tests::test_query_ready ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_instant_query ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_label_values_endpoint ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_labels_endpoint ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_query_with_labels ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_range_query ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_response_format ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_sum_aggregation ... ignored, requires running docker-compose stack\ntest e2e::smoke::prometheus_api_tests::test_prometheus_sum_by_aggregation ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_invalid_sql_returns_error ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_multiple_metrics_queryable ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_sql_aggregation_query ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_sql_query_with_filters ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_time_range_query ... ignored, requires running docker-compose stack\ntest e2e::smoke::roundtrip_tests::test_write_then_query_returns_data ... ignored, requires running docker-compose stack\ntest e2e::harness::tests::test_generate_cpu_samples ... ok\ntest e2e::harness::tests::test_sample_builder ... ok\ntest e2e::harness::tests::test_generate_test_samples ... ok\n\ntest result: ok. 3 passed; 0 failed; 19 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 7 tests\ntest test_complete_cluster_pipeline ... ok\ntest test_distributed_write_routing ... ok\ntest test_cost_optimization_full_stack ... ok\ntest test_ingestion_with_predicate_pushdown ... ok\ntest test_multi_tenant_isolation ... ok\ntest test_streaming_with_topic_filtering ... ok\ntest test_complete_query_pipeline ... ok\n\ntest result: ok. 7 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.12s\n\n\nrunning 32 tests\ntest test_error_source_chain ... ok\ntest test_error_display_formats ... ok\ntest test_get_chunks_for_nonexistent_shard ... ok\ntest test_compaction_job_lifecycle ... ok\ntest test_cas_stale_generation_error_format ... ok\ntest test_cas_max_generation_values ... ok\ntest test_get_nonexistent_chunk ... ok\ntest test_delete_nonexistent_chunk ... ok\ntest test_level_candidates_nonexistent_level ... ok\ntest test_get_chunks_empty_time_range ... ok\ntest test_list_chunks_uninitialized_metadata ... ok\ntest test_l0_candidates_empty ... ok\ntest test_compaction_with_single_source ... ok\ntest test_register_chunk_with_zero_timestamps ... ok\ntest test_register_duplicate_chunk_path ... ok\ntest test_timerange_contains_exact_boundaries ... ok\ntest test_timerange_from_range ... ok\ntest test_split_state_nonexistent_shard ... ok\ntest test_timerange_negative_timestamps ... ok\ntest test_timerange_overlaps_adjacent ... ok\ntest test_timerange_overlaps_disjoint ... ok\ntest test_timerange_overlaps_subset ... ok\ntest test_timerange_single_point ... ok\ntest test_timerange_zero_timestamps ... ok\ntest test_write_buffer_empty_operations ... ok\ntest test_metadata_cas_fails_loudly_when_unsafe_overwrite_disabled ... ok\ntest test_metadata_cas_fallback_overwrite_when_enabled ... ok\ntest test_concurrent_registration_data_integrity ... ok\ntest test_write_buffer_multiple_takes ... ok\ntest test_write_buffer_size_tracking ... ok\ntest test_ingester_buffer_below_threshold_no_flush ... ok\ntest test_ingester_flush_produces_valid_parquet ... ok\n\ntest result: ok. 32 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.04s\n\n\nrunning 9 tests\ntest test_new_shard_creation ... ok\ntest test_generation_increments ... ok\ntest test_cas_prevents_lost_updates ... ok\ntest test_independent_shard_updates ... ok\ntest test_cas_with_state_transitions ... ok\ntest test_nonexistent_shard ... ok\ntest test_retry_with_backoff ... ok\ntest test_concurrent_cas_updates ... ok\ntest test_stale_generation_rejected ... ok\n\ntest result: ok. 9 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 5 tests\ntest test_new_chunks_start_at_l0 ... ok\ntest test_level_filtering ... ok\ntest test_l0_to_l1_progression ... ok\ntest test_l1_to_l2_progression ... ok\ntest test_full_level_progression ... ok\n\ntest result: ok. 5 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s\n\n\nrunning 7 tests\ntest test_empty_result_optimization ... ok\ntest test_predicate_pushdown_between ... ok\ntest test_predicate_pushdown_with_in_list ... ok\ntest test_predicate_pushdown_with_ranges ... ok\ntest test_predicate_pushdown_with_and_or ... ok\ntest test_predicate_pushdown_reduces_chunks ... ok\ntest test_cost_reduction_simulation ... ok\n\ntest result: ok. 7 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.23s\n\n\nrunning 8 tests\ntest test_split_point_calculation ... ok\ntest test_phase1_preparation ... ok\ntest test_phase2_dualwrite_state ... ok\ntest test_phase4_cutover ... FAILED\ntest test_phase3_backfill ... ok\ntest test_backfill_progress_tracking ... ok\ntest test_phase5_cleanup ... ok\ntest test_full_split_execution has been running for over 60 seconds\ntest test_full_split_execution ... ok\n\nfailures:\n\n---- test_phase4_cutover stdout ----\n\nthread 'test_phase4_cutover' (3754107) panicked at tests/shard_split_tests.rs:208:45:\ncalled `Result::unwrap()` on an `Err` value: ShardNotFound(\"test-shard-1\")\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n\n\nfailures:\n    test_phase4_cutover\n\ntest result: FAILED. 7 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 310.02s currently fails at tests/shard_split_tests.rs:208 with ShardNotFound(\"test-shard-1\"). Align cutover preconditions with test setup, enforce clear invariants in code, and add regression coverage so phase-4 behavior is deterministic.","status":"tombstone","priority":0,"issue_type":"bug","created_at":"2026-02-16T16:35:25.058329-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.542395-07:00","deleted_at":"2026-02-16T16:42:15.542395-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"bug"}
{"id":"cardinalsin-b34.7","title":"Remove 300s test sleep from shard split full-flow tests","description":"test_full_split_execution currently spends ~300 seconds in cleanup grace period. Inject configurable grace period/time provider so tests complete in milliseconds while production retains safety windows.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2026-02-16T16:35:25.141416-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.542395-07:00","deleted_at":"2026-02-16T16:42:15.542395-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"task"}
{"id":"cardinalsin-b34.8","title":"Add cross-node metadata freshness mode for catalog cache","description":"S3 catalog cache currently relies on local TTL invalidation only. Add ETag revalidation / bypass mode for freshness-critical query paths to avoid stale reads across nodes after recent writes.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2026-02-16T16:35:25.242005-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:42:15.542396-07:00","deleted_at":"2026-02-16T16:42:15.542396-07:00","deleted_by":"jeremyudis","delete_reason":"delete","original_type":"task"}
{"id":"cardinalsin-b9n","title":"D-core: WAL segment management, entry format, config, unit tests","description":"CRITICAL: Eliminate 5-min data loss window on ingester crash. Implement Arrow IPC WAL per docs/design-wal.md. Create src/ingester/wal.rs with segment file management, WalConfig/WalSyncMode, CRC32 integrity, segment rotation. Add unit tests for CRC, rotation, truncation, corruption. Add Error::WalFull variant. ~350 LOC. Touches: src/ingester/wal.rs (new), src/error.rs. PARALLEL with Phase C (no file overlap).","notes":"Reopened: PR review found truncated WAL entry aborts recovery (should skip trailing incomplete entry, not error). Also init_wal() always returns None with no warning on write path.","status":"closed","priority":0,"issue_type":"feature","created_at":"2026-02-09T09:28:53.44773-07:00","created_by":"jeremyudis","updated_at":"2026-02-10T21:07:44.799047-07:00","closed_at":"2026-02-10T21:07:44.799047-07:00","close_reason":"P0-P1 fixes applied: WAL crash-tolerant recovery, WAL init warning, PutMode::Create for first write, complete_compaction target validation"}
{"id":"cardinalsin-buf","title":"B7: Deduplicate split_batch implementations","description":"Two identical split_batch_by_timestamp implementations exist: src/ingester/mod.rs:283 and src/sharding/splitter.rs:230. Extract to shared function in sharding module. ~50 LOC.","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-02-09T09:28:31.551419-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:47.493182-07:00","external_ref":"gh-42","dependencies":[{"issue_id":"cardinalsin-buf","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:32:31.151254-07:00","created_by":"import"}]}
{"id":"cardinalsin-bxh","title":"F5: Unify predicate type systems between streaming and engine","description":"Duplicate predicate extraction exists in streaming.rs and engine.rs. Unify into single type system. ~100 LOC. Touches: src/query/streaming.rs, src/query/engine.rs.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T09:29:35.469969-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T10:30:45.292717-07:00","closed_at":"2026-02-12T10:30:45.292717-07:00","close_reason":"PR #11 - unified predicate types, streaming uses ColumnPredicate"}
{"id":"cardinalsin-c5e","title":"EPIC: Self-Observability Hardening via OTel Dogfooding","description":"## Summary\nInstrument CardinalSin so the system can observe itself in real time during benchmark runs using an OpenTelemetry-first approach.\n\n## Why\nCurrent runtime has logging and protocol support, but lacks consistent internal telemetry coverage and turnkey dashboard workflow. We need dogfooding-grade observability as a hardening phase.\n\n## Objectives\n- OTel-native instrumentation first; custom metrics only where OTel does not provide sufficient signal.\n- Real-time Grafana visibility while mixed workloads run.\n- Queryability of system telemetry through CardinalSin surfaces.\n- Stable telemetry contract that prevents regressions.\n\n## Success Criteria\n- 30-60 minute mixed workload run with live dashboards for ingest/query/compaction/metadata health.\n- Critical metrics and top-level traces are emitted consistently from ingester, query, and compactor binaries.\n- Telemetry can be filtered by `run_id` for benchmark sessions.\n- Overhead guardrail: <=5% CPU regression and <=10% p99 latency regression relative to baseline.\n\n## Scope\nThis Epic owns the full implementation chain:\n1. Shared OTel bootstrap and config.\n2. Collector deployment wiring (local and k8s).\n3. API/gRPC instrumentation.\n4. Ingester/query/compactor/metadata instrumentation.\n5. Grafana provisioning and dashboard pack.\n6. Mixed-workload runner and telemetry query pack.\n7. Validation tests and operator runbook.\n\n## Policy (Locked)\n- Prefer first-party OTel integrations and semantic conventions.\n- Custom metrics are allowed but must include a documented reason in issue/PR notes.\n\n## Out of Scope\n- Deep per-function tracing across all modules.\n- Non-OTel logging pipeline redesign.\n- New product features unrelated to observability hardening.\n\n## Coordination\nChild issues under this Epic are decision-complete and execution-ready; agents should pick one issue at a time and preserve telemetry contract consistency.\n","status":"open","priority":0,"issue_type":"epic","created_at":"2026-02-21T15:12:11.866604-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:11.866604-07:00","external_ref":"gh-65"}
{"id":"cardinalsin-c5e.1","title":"Observability Foundation: Shared OTel Bootstrap and Config Contract","description":"Parent Epic: #65\n\n## Summary\nAdd a shared observability bootstrap used by all binaries so OTel initialization is consistent and centrally managed.\n\n## Background\nToday each binary initializes tracing independently. We need a single config-driven OTel bootstrap across services.\n\n## Scope\n- Add a shared module for telemetry initialization and shutdown lifecycle.\n- Wire binaries: \n  - \\'src/bin/ingester.rs\\'\n  - \\'src/bin/query.rs\\'\n  - \\'src/bin/compactor.rs\\'\n  - \\'src/bin/backfill_levels.rs\\'\n  - \\'src/bin/rebuild_metadata.rs\\'\n- Support env contract:\n  - \\'OTEL_SERVICE_NAME\\'\n  - \\'OTEL_EXPORTER_OTLP_ENDPOINT\\'\n  - \\'OTEL_EXPORTER_OTLP_PROTOCOL\\'\n  - \\'OTEL_RESOURCE_ATTRIBUTES\\'\n  - \\'OTEL_TRACES_SAMPLER\\'\n  - \\'OTEL_TRACES_SAMPLER_ARG\\'\n  - \\'CARDINALSIN_TELEMETRY_RUN_ID\\'\n- Define service/resource attributes and defaults.\n\n## Acceptance Criteria\n- All binaries start with shared bootstrap.\n- Invalid config fails fast with actionable error message.\n- OTel enable/disable behavior is environment-driven.\n- Startup logs clearly report telemetry mode and exporter endpoint.\n\n## Notes\nPrefer OTel-native setup and semantic conventions; avoid ad-hoc custom init paths.\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-21T15:12:11.9708-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:11.9708-07:00","external_ref":"gh-66","dependencies":[{"issue_id":"cardinalsin-c5e.1","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:11.971787-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c5e.10","title":"Telemetry Query Pack (SQL + Prometheus API)","description":"Parent Epic: #65\n\n## Summary\nShip a query pack (SQL + Prometheus API) for inspecting system telemetry from CardinalSin itself.\n\n## Scope\n- Add query pack docs/scripts for:\n  - ingestion throughput and errors\n  - query latency and error rates\n  - compaction backlog and activity\n  - metadata CAS contention\n  - cache effectiveness\n- Provide both live run and post-run forensic query sets.\n- Ensure query pack aligns with metric catalog and dashboard panels.\n\n## Acceptance Criteria\n- Query pack executes successfully against running benchmark environment.\n- Output is immediately useful for diagnosing run regressions.\n- Queries are documented with expected shape/interpretation.\n","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-21T15:12:12.858833-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:12.858833-07:00","external_ref":"gh-75","dependencies":[{"issue_id":"cardinalsin-c5e.10","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.859698-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c5e.11","title":"Telemetry Validation Suite and CI Guardrails","description":"Parent Epic: #65\n\n## Summary\nAdd telemetry validation guardrails in tests/CI to prevent regressions in signal coverage and performance overhead.\n\n## Scope\n- Add integration tests asserting critical telemetry emission for key paths.\n- Add schema contract checks against metric catalog.\n- Add overhead check workflow for benchmark-mode regression budget.\n- Ensure CI fails when critical metrics disappear or contract breaks.\n\n## Acceptance Criteria\n- CI includes telemetry contract validation.\n- CI reports instrumentation overhead vs baseline.\n- Regression in required telemetry blocks merges.\n","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-21T15:12:12.959202-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:12.959202-07:00","external_ref":"gh-76","dependencies":[{"issue_id":"cardinalsin-c5e.11","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.95989-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c5e.12","title":"Operator Runbook for Real-Time Observability Dogfooding","description":"Parent Epic: #65\n\n## Summary\nWrite operator runbook for real-time dogfooding workflow from startup to diagnosis.\n\n## Scope\n- Update \\'README.md\\' and add \\'docs/observability-dogfooding-runbook.md\\'.\n- Include:\n  - startup steps\n  - benchmark execution\n  - Grafana dashboard usage\n  - query pack usage\n  - troubleshooting for collector/exporter/dashboard failures\n- Link each runbook step to relevant dashboards and queries.\n\n## Acceptance Criteria\n- New engineer can reproduce full workflow without tribal knowledge.\n- Troubleshooting section covers common failure modes.\n- Runbook matches actual repository commands/config.\n","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-21T15:12:13.059985-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:13.059985-07:00","external_ref":"gh-77","dependencies":[{"issue_id":"cardinalsin-c5e.12","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:13.060748-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c5e.2","title":"Deploy OTel Collector for Local and Kubernetes Telemetry Path","description":"Parent Epic: #65\n\n## Summary\nDeploy a standard OTel Collector path for local docker-compose and Kubernetes so service telemetry flows through collector -> CardinalSin ingest.\n\n## Scope\n- Add collector config under \\'deploy/otel-collector/\\'.\n- Update \\'deploy/docker-compose.yml\\' with collector service and env wiring for ingester/query/compactor.\n- Update \\'deploy/kubernetes/ingester.yaml\\', \\'deploy/kubernetes/query.yaml\\', and \\'deploy/kubernetes/compactor.yaml\\' with collector exporter env vars.\n- Validate OTLP path to ingester receiver.\n\n## Acceptance Criteria\n- \\'docker-compose up\\' brings up collector and telemetry pipeline works end-to-end.\n- Kubernetes manifests have equivalent collector wiring.\n- Collector retries/backoff behavior is validated.\n- Basic troubleshooting section is documented.\n","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-02-21T15:12:12.069678-07:00","created_by":"jeremyudis","updated_at":"2026-02-22T17:44:53Z","external_ref":"gh-67","dependencies":[{"issue_id":"cardinalsin-c5e.2","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.070494-07:00","created_by":"jeremyudis"}],"closed_at":"2026-02-22T17:44:53Z","close_reason":"Closed via merged PR #79 (https://github.com/jeremyudis/cardinalsin/pull/79) for GitHub issue #67"}
{"id":"cardinalsin-c5e.3","title":"HTTP and gRPC Instrumentation via OTel-Native Rust Integrations","description":"Parent Epic: #65\n\n## Summary\nInstrument HTTP and gRPC server surfaces using OTel-native Rust integrations first.\n\n## Scope\n- Add OTel middleware/interceptors for Axum and Tonic surfaces:\n  - \\'src/api/mod.rs\\'\n  - \\'src/api/grpc.rs\\'\n- Cover endpoint families:\n  - HTTP: \\'/health\\', \\'/ready\\', SQL, Prometheus API, remote write, stream.\n  - gRPC: OTLP export service, Flight ingest, Flight SQL.\n- Emit standard request metrics and top-level spans with semantic attributes.\n- Add status-code based error accounting.\n\n## Acceptance Criteria\n- Every endpoint emits request count + duration + error signals.\n- gRPC and HTTP telemetry uses OTel conventions where available.\n- No custom endpoint metric when equivalent OTel metric exists.\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-21T15:12:12.166977-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:12.166977-07:00","external_ref":"gh-68","dependencies":[{"issue_id":"cardinalsin-c5e.3","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.167697-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c5e.4","title":"Ingester Telemetry Coverage (Write, Flush, WAL, Backpressure)","description":"Parent Epic: #65\n\n## Summary\nAdd ingester-path telemetry to expose write health, buffering, flushing, and WAL behavior.\n\n## Scope\n- Instrument \\'src/ingester/mod.rs\\' for:\n  - write latency and throughput\n  - batch size and buffer fullness\n  - flush trigger reason (time/rows/bytes)\n  - flush duration and bytes flushed\n  - WAL append/replay/truncate outcomes\n  - split-aware/dual-write path counters\n- Use OTel metrics first; introduce custom \\'cardinalsin.*\\' metrics only for domain internals not covered by standard signals.\n- Bound label cardinality for shard/tenant dimensions.\n\n## Acceptance Criteria\n- Dashboard can diagnose ingest bottlenecks without reading logs.\n- WAL health and recovery behavior is visible.\n- Custom metrics include justification where OTel coverage is insufficient.\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-21T15:12:12.265064-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:12.265064-07:00","external_ref":"gh-69","dependencies":[{"issue_id":"cardinalsin-c5e.4","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.265799-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c5e.5","title":"Query Telemetry Coverage (Latency, Pruning, Cache, Failures)","description":"Parent Epic: #65\n\n## Summary\nInstrument query path so performance and failure causes are visible in real time.\n\n## Scope\n- Instrument \\'src/query/mod.rs\\' and \\'src/query/engine.rs\\'.\n- Emit:\n  - query latency histogram (p50/p95/p99)\n  - query success/error counts\n  - rows returned and bytes scanned/read\n  - chunk registration counts\n  - metadata pruning effectiveness\n  - cache hit/miss/eviction and cache sizes\n- Add minimal top-level query spans with correlation fields (including run_id).\n\n## Acceptance Criteria\n- Query performance dashboard can isolate cache, pruning, and execution bottlenecks.\n- Error taxonomy is visible and actionable.\n- Metrics schema is stable and documented.\n","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-02-21T15:12:12.363524-07:00","created_by":"jeremyudis","updated_at":"2026-02-22T17:45:43Z","external_ref":"gh-70","dependencies":[{"issue_id":"cardinalsin-c5e.5","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.364257-07:00","created_by":"jeremyudis"}],"closed_at":"2026-02-22T17:45:43Z","close_reason":"Closed via merged PR #80 (https://github.com/jeremyudis/cardinalsin/pull/80) for GitHub issue #70"}
{"id":"cardinalsin-c5e.6","title":"Compactor + Metadata CAS + Sharding Telemetry Coverage","description":"Parent Epic: #65\n\n## Summary\nInstrument compaction lifecycle, metadata CAS operations, and shard split orchestration signals.\n\n## Scope\n- Instrument:\n  - \\'src/compactor/mod.rs\\'\n  - \\'src/metadata/s3.rs\\'\n  - \\'src/sharding/monitor.rs\\'\n- Emit:\n  - compaction cycle duration\n  - active compactions\n  - pending L0 count and backpressure state\n  - lease conflicts and renewal failures\n  - CAS retries/conflicts/success\n  - GC deletion success/failure\n  - split phase progress and failure counters\n- Keep trace depth minimal (top-level operation spans only).\n\n## Acceptance Criteria\n- Operators can detect and explain compaction lag and metadata contention from metrics.\n- Split progress and failures are visible from telemetry alone.\n- Telemetry is safe from runaway cardinality.\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-21T15:12:12.461649-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:12.461649-07:00","external_ref":"gh-71","dependencies":[{"issue_id":"cardinalsin-c5e.6","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.462375-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c5e.7","title":"Telemetry Contract: Metric Catalog and Label Governance","description":"Parent Epic: #65\n\n## Summary\nCreate and enforce a telemetry contract document for all dashboards/tests.\n\n## Scope\n- Add \\'docs/telemetry/metric-catalog.md\\'.\n- For each metric, define:\n  - name\n  - type/unit\n  - required labels\n  - source module/file\n  - semantic convention mapping\n  - custom metric justification (if applicable)\n- Document prohibited high-cardinality labels and naming rules.\n\n## Acceptance Criteria\n- Every dashboard panel metric is present in catalog.\n- Every custom metric has documented reason.\n- Contract is used by validation tests to prevent silent regressions.\n","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-21T15:12:12.558925-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:12.558925-07:00","external_ref":"gh-72","dependencies":[{"issue_id":"cardinalsin-c5e.7","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.559662-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c5e.8","title":"Grafana Provisioning: Datasource + Internal Dogfooding Dashboards","description":"Parent Epic: #65\n\n## Summary\nProvision Grafana datasource and dashboards in-repo for zero-manual-setup observability.\n\n## Scope\n- Populate \\'deploy/grafana/provisioning/\\' with:\n  - datasource provisioning\n  - dashboard provisioning\n  - dashboard JSON files\n- Create dashboards:\n  - ingest health\n  - query performance\n  - compactor + metadata CAS health\n  - benchmark run overview\n- Include template filters for \\'run_id\\', service, and tenant.\n\n## Acceptance Criteria\n- Fresh \\'docker-compose up\\' loads datasource and dashboards automatically.\n- Dashboards populate live during workload runs.\n- Dashboard assets are versioned in repository.\n","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-21T15:12:12.66069-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:12.66069-07:00","external_ref":"gh-73","dependencies":[{"issue_id":"cardinalsin-c5e.8","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.661408-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c5e.9","title":"Mixed Workload Runner with run_id Telemetry Correlation","description":"Parent Epic: #65\n\n## Summary\nImplement a reproducible 30-60 minute mixed workload runner with telemetry correlation.\n\n## Scope\n- Build one-command workflow for:\n  - ingest load (existing generator path in \\'src/bin/test_data_generator.rs\\')\n  - concurrent query load\n  - active compactor behavior observation\n- Propagate and expose a benchmark \\'run_id\\' in telemetry attributes.\n- Persist run metadata/artifacts under \\'benchmarks/results/\\'.\n\n## Acceptance Criteria\n- Single command starts mixed run and prints run_id.\n- Grafana and query pack can filter all metrics by run_id.\n- End-of-run summary includes pass/fail against target KPIs.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-21T15:12:12.760935-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T15:12:12.760935-07:00","external_ref":"gh-74","dependencies":[{"issue_id":"cardinalsin-c5e.9","depends_on_id":"cardinalsin-c5e","type":"parent-child","created_at":"2026-02-21T15:12:12.761664-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c9k","title":"Make shard split backfill idempotent and resume-safe","description":"`ShardSplitter::run_backfill` currently iterates all old-shard chunks on each run and does not persist per-chunk completion. On resume after crash, already-copied chunks can be copied again, creating duplicate data and non-deterministic outcomes.\n\nScope:\n- Persist per-source-chunk (or chunk+row-range) backfill completion in split progress state\n- Ensure resume only processes remaining work\n- Make writes idempotent for retries (safe overwrite/upsert semantics or deterministic target IDs)\n- Add regression tests for crash between partial backfill iterations and successful resume\n\nCode refs: `src/sharding/splitter.rs` (run_backfill, persist_progress).","notes":"Started implementation: persisted per-chunk backfill completion, deterministic backfill target paths, and idempotency regression test.","status":"in_progress","priority":0,"issue_type":"bug","created_at":"2026-02-21T14:06:20.603356-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T14:19:27.305118-07:00","dependencies":[{"issue_id":"cardinalsin-c9k","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-21T14:06:20.604657-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c9m","title":"Fix dual-write query dedup key to avoid dropping distinct rows","description":"Current dedup in `src/query/dedup.rs` uses only `(timestamp, metric_name)` as the key. This can incorrectly drop valid rows that differ by labels/value but share timestamp+metric during split dual-write windows.\n\nScope:\n- Expand dedup identity to include full series identity (labels + metric + timestamp, and value if needed)\n- Keep behavior deterministic across batches/orderings\n- Add tests covering same timestamp+metric with different labels/values\n- Validate no false positives on normal multi-series queries\n\nCode refs: `src/query/dedup.rs`, `src/query/mod.rs` (dedup invocation).","status":"open","priority":1,"issue_type":"bug","created_at":"2026-02-21T14:06:35.748801-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T14:06:35.748801-07:00","dependencies":[{"issue_id":"cardinalsin-c9m","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-21T14:06:35.750299-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c9n","title":"Implement distributed write/query forwarding in cluster routers","description":"WriteRouter::forward_write and QueryRouter::execute_on_node still contain TODO/no-op paths that keep behavior effectively local-only. This blocks functional completeness for multi-node deployments and can hide correctness issues behind single-node tests.\n\nScope:\n- Implement real remote forwarding for writes from src/cluster/write_router.rs (RPC/transport call + error/timeout handling)\n- Implement remote query execution in src/cluster/query_router.rs with per-node partial-failure semantics\n- Replace naive in-memory merge with deterministic, schema-safe merge behavior\n- Add integration tests with >=2 nodes covering fanout, partial node failure, and merged results\n\nCode refs: src/cluster/write_router.rs, src/cluster/query_router.rs, cluster service wiring in src/bin/ingester.rs and src/bin/query.rs.\n","status":"open","priority":0,"issue_type":"feature","created_at":"2026-02-21T14:08:24.635618-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T14:08:24.635618-07:00","dependencies":[{"issue_id":"cardinalsin-c9n","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-21T14:08:24.636875-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c9p","title":"Add crash-consistency and fault-injection coverage for metadata/split/compaction","description":"Critical durability paths (metadata CAS updates, compaction leases, and shard split progress) lack explicit crash/fault-injection coverage. Current tests mostly verify happy-path behavior, leaving restart and partial-write edge cases under-tested.\n\nScope:\n- Add targeted fault-injection hooks/tests around metadata writes in src/metadata/s3.rs to simulate failures between temp write, copy, and delete stages\n- Add crash-resume tests for split progress transitions in src/sharding/splitter.rs and lease lifecycle in src/compactor/mod.rs\n- Verify idempotent retry behavior and invariant preservation (no orphaned state, no duplicate data registration)\n- Add CI-suitable deterministic test variants for these failure modes\n\nCode refs: src/metadata/s3.rs, src/sharding/splitter.rs, src/compactor/mod.rs, tests/* integration suites.\n","status":"open","priority":0,"issue_type":"bug","created_at":"2026-02-21T14:08:36.78882-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T14:08:36.78882-07:00","dependencies":[{"issue_id":"cardinalsin-c9p","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-21T14:08:36.790103-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-c9q","title":"Establish deterministic TSDB benchmark harness and regression gates","description":"Benchmark guidance exists in docs/benchmark-improvement-plan.md but there is no deterministic, continuously-runnable harness that proves regressions against TSDB goals. This leaves performance claims and tradeoff decisions weakly validated.\n\nScope:\n- Implement a reproducible benchmark harness aligned with TSBS-style workloads (ingest throughput, query latency, mixed read/write)\n- Check in deterministic dataset/profile definitions and execution scripts\n- Persist baseline results and add pass/fail regression thresholds for key metrics\n- Add developer docs for running benchmarks locally and in CI-adjacent environments\n\nCode/docs refs: docs/benchmark-improvement-plan.md, benches/, scripts/, CI workflow files.\n","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-21T14:08:49.081008-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T14:08:49.081008-07:00","dependencies":[{"issue_id":"cardinalsin-c9q","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-21T14:08:49.082451-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-d6s","title":"D-core: WAL ack/fsync semantics decision","description":"Decide ack behavior (after WAL append vs after fsync). Update write path + tests accordingly.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-10T00:09:47.795841-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T00:25:29.669674-07:00","closed_at":"2026-02-12T00:25:29.669674-07:00","close_reason":"Ack after WAL append (not fsync), documented on write() method"}
{"id":"cardinalsin-dh2","title":"Wire adaptive indexing controller into query runtime","description":"Adaptive indexing subsystem exists under src/adaptive_index, but query service startup does not instantiate or run AdaptiveIndexController. As a result, index lifecycle and recommendation loops remain inactive in normal deployments.\n\nScope:\n- Add config/env toggles for adaptive indexing in query binary.\n- Create and run controller loop at startup.\n- Wire query execution stats collection to controller inputs.\n- Add integration tests demonstrating invisible->visible lifecycle transitions.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-02-21T14:13:15.111745-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T14:21:46.914623-07:00","external_ref":"gh-60"}
{"id":"cardinalsin-exk","title":"E11: Fix trivially-true assertion tests","description":"Several tests have assertions that are always true (e.g. assert!(x >= 0) for unsigned). Replace with meaningful assertions. ~80 LOC. Touches: various test files.","notes":"Assigned to merged Agent B with sibling test-hardening issues due high probability of touching the same test modules and assertion blocks.\nValidated in worktree fix/309-c-validation after merged PR #53: no remaining trivially-true assertion patterns found in tests via repository scan; adaptive and atomic metadata hardening tests pass.","status":"closed","priority":1,"issue_type":"bug","assignee":"jeremyudis","created_at":"2026-02-09T09:29:19.530517-07:00","created_by":"jeremyudis","updated_at":"2026-02-19T11:52:14.366006-07:00","closed_at":"2026-02-19T11:52:14.366234-07:00","external_ref":"gh-35","dependencies":[{"issue_id":"cardinalsin-exk","depends_on_id":"cardinalsin-309","type":"parent-child","created_at":"2026-02-16T16:32:31.152402-07:00","created_by":"import"}]}
{"id":"cardinalsin-gv9","title":"Implement or remove GCS/Azure backend support in ComponentFactory","description":"Cargo features enable aws, gcp, and azure providers in object_store, but runtime factory currently supports only STORAGE_BACKEND=memory or s3.\n\nScope:\n- Either add gcs/azure backend options and required config wiring, or narrow dependency/docs to S3-only runtime support.\n- Add tests to ensure docs and runtime support matrix stay aligned.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-21T14:13:10.122855-07:00","created_by":"jeremyudis","updated_at":"2026-02-21T14:21:46.921023-07:00","external_ref":"gh-62"}
{"id":"cardinalsin-iry","title":"E1-E5: Compaction leasing implementation","description":"Implement per docs/design-compaction-leasing.md. Add CompactionLease/LeaseStatus/CompactionLeases types, compaction_leases_path(), lease CRUD with CAS, integrate into compact_l0/compact_level, add lease renewal background task, add scavenging. Add Error::ChunksAlreadyLeased. Add node_id to Compactor. ~580 LOC. Depends on: Phase C (benefits from AtomicJsonStore but not strictly required).","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-02-09T09:29:00.210308-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T09:33:32.024774-07:00","closed_at":"2026-02-12T09:33:32.024774-07:00","close_reason":"PR #7 - Full compaction leasing implementation per design doc: CAS-based S3 leases, lease renewal, scavenging, 17 integration tests"}
{"id":"cardinalsin-jey","title":"B2: MinIO CAS fallback - fail loud instead of silent PutMode::Overwrite","notes":"2026-02-16: Tightening MinIO behavior: CAS remains default-safe (fail loud), with explicit allow_unsafe_overwrite opt-in for local MinIO-only workflows. Adding regression tests for both disabled and enabled modes.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-08T22:14:23.155722-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:05:07.467313-07:00","closed_at":"2026-02-16T16:05:07.467313-07:00","close_reason":"Implemented safe-by-default CAS behavior for MinIO/object stores without conditional PUT support; unsafe overwrite is explicit opt-in via allow_unsafe_overwrite/S3_METADATA_ALLOW_UNSAFE_OVERWRITE. Added regression tests for fail-loud default and explicit opt-in fallback."}
{"id":"cardinalsin-mgk","title":"F3: Shard split cutover atomicity with fencing tokens","description":"Cutover makes 3 separate update_shard_metadata calls without fencing. Crash between them leaves partial key space coverage. Add fencing tokens. ~150 LOC. Touches: src/sharding/splitter.rs.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T09:29:28.380937-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T15:04:03.662104-07:00","closed_at":"2026-02-12T15:04:03.662104-07:00","close_reason":"Added CutoverIntent with fencing tokens and resume_cutover(). PR #16."}
{"id":"cardinalsin-q8u","title":"E8: Persist pending_deletions across compactor restarts","description":"pending_deletions is RwLock<Vec> in-memory only. Compactor restart loses all pending deletions, leaking S3 storage. Persist to S3 file. ~40 LOC. Touches: src/compactor/mod.rs.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T09:29:09.721396-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T10:03:34.885395-07:00","closed_at":"2026-02-12T10:03:34.885395-07:00","close_reason":"PR #9 - pending_deletions persisted to S3"}
{"id":"cardinalsin-s6s","title":"E9: Fix 12 tests that accept both Ok and Err","description":"~12 integration tests use patterns like 'assert\\!(result.is_ok() || result.is_err())' or match both Ok/Err arms identically. These provide zero regression value. Fix each to assert specific expected outcomes. ~200 LOC. Touches: tests/shard_split_tests.rs, tests/cluster_tests.rs, others.","notes":"Assigned to merged Agent B with sibling test-hardening issues due high probability of touching the same test modules and assertion blocks.\nValidated in worktree fix/309-c-validation after merged PR #53: no remaining accept-both-Ok/Err patterns found in tests via repository scan; hardening behavior verified with targeted test run.","status":"closed","priority":1,"issue_type":"bug","assignee":"jeremyudis","created_at":"2026-02-09T09:29:12.45121-07:00","created_by":"jeremyudis","updated_at":"2026-02-19T11:52:14.472034-07:00","closed_at":"2026-02-19T11:52:14.472038-07:00","external_ref":"gh-36","dependencies":[{"issue_id":"cardinalsin-s6s","depends_on_id":"cardinalsin-309","type":"parent-child","created_at":"2026-02-16T16:32:31.153563-07:00","created_by":"import"}]}
{"id":"cardinalsin-t86","title":"E7: Clean up unbounded compaction job list","description":"CompactionStatus::Completed/Failed jobs never removed from compaction-jobs.json. File grows unbounded. Add cleanup of completed/failed jobs older than TTL in run_compaction_cycle(). ~60 LOC. Touches: src/metadata/s3.rs.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T09:29:07.577064-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T00:36:59.208258-07:00","closed_at":"2026-02-12T00:36:59.208258-07:00","close_reason":"PR #6 - TTL cleanup for compaction jobs with created_at timestamp, CAS-safe S3 impl, 1hr TTL in compaction cycle"}
{"id":"cardinalsin-tu8","title":"B6: Replace DefaultHasher with stable hash for shard keys","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-02-08T22:14:23.407938-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:43.500438-07:00","external_ref":"gh-37","dependencies":[{"issue_id":"cardinalsin-tu8","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:32:31.15499-07:00","created_by":"import"}]}
{"id":"cardinalsin-u57","title":"B9: Remove unused dependencies (once_cell, config, hex)","description":"once_cell (line 110), config (line 120), hex are in Cargo.toml but unused. Remove them to speed up compile times. ~10 LOC. Verify with cargo check.","notes":"2026-02-16 reassessment: dependencies once_cell, config, and hex are still present in Cargo.toml and appear unused in src/tests.","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-09T09:28:35.562215-07:00","created_by":"jeremyudis","updated_at":"2026-02-16T16:45:49.80518-07:00","close_reason":"Removed once_cell, config, hex. PR #14.","external_ref":"gh-44","dependencies":[{"issue_id":"cardinalsin-u57","depends_on_id":"cardinalsin-b34","type":"parent-child","created_at":"2026-02-16T16:33:13.894187-07:00","created_by":"import"}]}
{"id":"cardinalsin-vis","title":"F2: Dual-write deduplication during shard split","description":"During dual-write phase, data exists in both old and new shards. Queries return duplicates. Add dedup mechanism. ~150 LOC. Depends on: F1. Touches: src/ingester/mod.rs, src/query/engine.rs.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T09:29:26.046198-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T15:11:59.258465-07:00","closed_at":"2026-02-12T15:11:59.258465-07:00","close_reason":"Added dedup_batches() and has_active_split() for dual-write dedup. PR #18.","dependencies":[{"issue_id":"cardinalsin-vis","depends_on_id":"cardinalsin-69s","type":"blocks","created_at":"2026-02-09T09:29:53.038345-07:00","created_by":"jeremyudis"}]}
{"id":"cardinalsin-vla","title":"D-core: WAL flush integration + truncation","description":"Integrate WAL truncation with successful flush to S3/metadata. Persist last flushed seq, truncate WAL segments, and wire in flush path.","status":"closed","priority":0,"issue_type":"feature","created_at":"2026-02-10T00:09:30.182218-07:00","created_by":"jeremyudis","updated_at":"2026-02-10T21:42:17.115037-07:00","closed_at":"2026-02-10T21:42:17.115037-07:00","close_reason":"Flush integration done - truncate_before + persist_flushed_seq after S3 flush"}
{"id":"cardinalsin-xcw","title":"E12: Add graceful shutdown to all service loops","description":"run_flush_timer and Compactor::run use infinite loops with no CancellationToken or shutdown signal. Add tokio watch/CancellationToken for clean shutdown. ~100 LOC. Touches: src/ingester/mod.rs, src/compactor/mod.rs.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T09:29:21.561779-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T10:06:41.52939-07:00","closed_at":"2026-02-12T10:06:41.52939-07:00","close_reason":"PR #10 - CancellationToken for Compactor and Ingester"}
{"id":"cardinalsin-xjy","title":"C: Metadata merge - unify metadata.json + time-index.json into catalog.json","description":"CRITICAL: Eliminate non-atomic two-file CAS (#1 finding in both audits). Implement design from docs/design-metadata-merge.md. Add MetadataCatalog struct with shard_id field, implement load_catalog_with_etag() with dual-read fallback, atomic_save_catalog() single-file CAS, rewrite atomic_register_chunk/delete_chunk/complete_compaction to use catalog, replace dual cache with single catalog_cache, update get_chunks_for_shard to use shard_id field. ~480 LOC core. Touches: src/metadata/s3.rs primarily.","notes":"Reopened: PR review found first catalog write uses PutMode::Overwrite (should be Create), and legacy fallback discards ETags defeating CAS during migration.","status":"closed","priority":0,"issue_type":"feature","created_at":"2026-02-09T09:28:45.510079-07:00","created_by":"jeremyudis","updated_at":"2026-02-10T21:07:44.826496-07:00","closed_at":"2026-02-10T21:07:44.826496-07:00","close_reason":"P0-P1 fixes applied: WAL crash-tolerant recovery, WAL init warning, PutMode::Create for first write, complete_compaction target validation"}
{"id":"cardinalsin-zxy","title":"F4: Clock skew mitigation for timestamps","description":"Uses chrono::Utc::now() for chunk paths and retention. Clock skew causes premature deletion or retention violations. Add hybrid logical clock or NTP-aware bounds. ~80 LOC.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-02-09T09:29:33.669465-07:00","created_by":"jeremyudis","updated_at":"2026-02-12T15:00:41.020078-07:00","closed_at":"2026-02-12T15:00:41.020078-07:00","close_reason":"Added BoundedClock with monotonic guarantees and skew-safe retention. PR #15."}
